{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0Ej_bXyQvnV"
      },
      "source": [
        "# Compute performance metrics for the given Y and Y_score without sklearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4CHb6NE7Qvnc"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "# other than these two you should not import any other packages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KbsWXuDaQvnq"
      },
      "source": [
        "\n",
        "## A. Compute performance metrics for the given data '5_a.csv'\n",
        " <pre>  <b>Note 1:</b> in this data you can see number of positive points >> number of negatives points\n",
        "   <b>Note 2:</b> use pandas or numpy to read the data from <b>5_a.csv</b>\n",
        "   <b>Note 3:</b> you need to derive the class labels from given score</pre> $y^{pred}= \\text{[0 if y_score < 0.5 else 1]}$\n",
        "\n",
        "<pre>\n",
        "<ol>\n",
        "<li> Compute Confusion Matrix </li>\n",
        "<li> Compute F1 Score </li>\n",
        "<li> Compute AUC Score, you need to compute different thresholds and for each threshold compute tpr,fpr and then use               numpy.trapz(tpr_array, fpr_array) <a href='https://stackoverflow.com/q/53603376/4084039'>https://stackoverflow.com/q/53603376/4084039</a>, <a href='https://stackoverflow.com/a/39678975/4084039'>https://stackoverflow.com/a/39678975/4084039</a> Note: it should be numpy.trapz(tpr_array, fpr_array) not numpy.trapz(fpr_array, tpr_array)\n",
        "Note- Make sure that you arrange your probability scores in descending order while calculating AUC</li>\n",
        "<li> Compute Accuracy Score </li>\n",
        "</ol>\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WaFLW7oBQvnt",
        "scrolled": true,
        "outputId": "bfc7a096-8c78-4507-c44d-358903a5010c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "performance matreix is [[0, 0], [100, 10000]]\n",
            "F1 score is 0.9950248756218906\n",
            "Accuracy score is 0.9900990099009901\n",
            "AUC score is 0.5117010000000091\n"
          ]
        }
      ],
      "source": [
        "df_a=pd.read_csv('5_a.csv')\n",
        "#create list of probablity values\n",
        "df_a_proba=list(df_a[\"proba\"])\n",
        "df_proba_descend=sorted(df_a_proba,reverse=True) #probablity list in descending order\n",
        "\n",
        "y_actual=list(df_a['y'])              #list of labels actual\n",
        "#create a list of tuple consisting of prob value and label\n",
        "prob_tupl=[(df_a_proba[i],y_actual[i]) for i in range (len(df_a_proba))]\n",
        "prob_tupl.sort(key=lambda x: x[0],reverse=True)       #reverse order\n",
        "\n",
        "#seperate tuple into two lists\n",
        "lst_final_proba=[]\n",
        "lst_final_y=[]\n",
        "for i in range (len(prob_tupl)):\n",
        "    lst_final_proba.append(prob_tupl[i][0])\n",
        "    lst_final_y.append(prob_tupl[i][1])\n",
        "\n",
        "y_predicted=[]              #converting prob values into labels\n",
        "for i in df_a_proba:\n",
        "    if i>=0.5:\n",
        "        y_predicted.append(1)\n",
        "    else:\n",
        "        y_predicted.append(0)\n",
        "\n",
        "def performance_matrix (list1,list2):\n",
        "    TP=0\n",
        "    FP=0\n",
        "    FN=0\n",
        "    TN=0\n",
        "    listt1=[]\n",
        "    listt2=[]\n",
        "\n",
        "    for i in range (len(list1)):\n",
        "        if list1[i]==list2[i]==1:\n",
        "            TP+=1\n",
        "        elif list1[i]==0 and list2[i]==1:\n",
        "            FP+=1\n",
        "        elif list1[i]==1 and list2[i]==0:\n",
        "            FN+=1\n",
        "        else:\n",
        "            TN+=1\n",
        "    listt1.extend([TN,FN])\n",
        "    listt2.extend([FP,TP])\n",
        "    perform_matrix=[listt1,listt2]\n",
        "    print(\"performance matreix is\", perform_matrix)\n",
        "\n",
        "    #calculation of f1-score\n",
        "    pr=TP/(TP+FP)        #precision\n",
        "    rec=TP/(FN+TP)       #recall\n",
        "\n",
        "    f1_score=(2*pr*rec)/(pr+rec)\n",
        "    print(\"F1 score is\", f1_score)\n",
        "    accu_score=(TN+TP)/(TN+TP+FN+FP)\n",
        "    print (\"Accuracy score is\", accu_score)\n",
        "performance_matrix (y_actual,y_predicted)\n",
        "\n",
        "tpr_list=[]\n",
        "fpr_list=[]\n",
        "\n",
        "def auc_score (list1,list2):\n",
        "    new_predict=[]\n",
        "    for i in list1:\n",
        "        for j in range(len(list1)):\n",
        "            if list1[j]>=i:\n",
        "                new_predict.append(1)\n",
        "            else:\n",
        "                new_predict.append(0)\n",
        "        tp=0\n",
        "        fp=0\n",
        "        fn=0\n",
        "        tn=0\n",
        "        for k in range(len(list1)):\n",
        "            if new_predict[k]==list2[k]==1:\n",
        "                tp+=1\n",
        "            elif new_predict[k]==1 and list2[k]==0:\n",
        "                fp+=1\n",
        "            elif new_predict[k]==0 and list2[k]==1:\n",
        "                fn+=1\n",
        "            else:\n",
        "                tn+=1\n",
        "        tpr=tp/(tp+fn)\n",
        "        fpr=fp/(tn+fp)\n",
        "        tpr_list.append(tpr)\n",
        "        fpr_list.append(fpr)\n",
        "\n",
        "        new_predict=[]\n",
        "\n",
        "    trap_coordi=[]\n",
        "    for i in range(len(tpr_list)-1):\n",
        "        trap_coordi.append(((fpr_list[i]+fpr_list[i+1])/2)*(tpr_list[i+1]-tpr_list[i]))\n",
        "\n",
        "    sum=0\n",
        "    for i in range (len(trap_coordi)):\n",
        "        sum+=trap_coordi[i]\n",
        "    print (\"AUC score is\",sum)\n",
        "\n",
        "auc_score(lst_final_proba,lst_final_y)\n",
        "\n",
        "\n",
        "# plt.plot (tpr_list,fpr_list)\n",
        "# plt.show\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5KZem1BQvn2"
      },
      "source": [
        "\n",
        "\n",
        "## B. Compute performance metrics for the given data '5_b.csv'\n",
        "<pre>\n",
        "   <b>Note 1:</b> in this data you can see number of positive points << number of negatives points\n",
        "   <b>Note 2:</b> use pandas or numpy to read the data from <b>5_b.csv</b>\n",
        "   <b>Note 3:</b> you need to derive the class labels from given score</pre> $y^{pred}= \\text{[0 if y_score < 0.5 else 1]}$\n",
        "\n",
        "<pre>\n",
        "<ol>\n",
        "<li> Compute Confusion Matrix </li>\n",
        "<li> Compute F1 Score </li>\n",
        "<li> Compute AUC Score, you need to compute different thresholds and for each threshold compute tpr,fpr and then use               numpy.trapz(tpr_array, fpr_array) <a href='https://stackoverflow.com/q/53603376/4084039'>https://stackoverflow.com/q/53603376/4084039</a>, <a href='https://stackoverflow.com/a/39678975/4084039'>https://stackoverflow.com/a/39678975/4084039</a>\n",
        "Note- Make sure that you arrange your probability scores in descending order while calculating AUC</li>\n",
        "<li> Compute Accuracy Score </li>\n",
        "</ol>\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U2sKlq0YQvn5",
        "outputId": "778d4d43-1b93-4e2c-819c-13fa323cc099"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>y</th>\n",
              "      <th>proba</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.281035</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.465152</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.352793</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.157818</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.276648</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     y     proba\n",
              "0  0.0  0.281035\n",
              "1  0.0  0.465152\n",
              "2  0.0  0.352793\n",
              "3  0.0  0.157818\n",
              "4  0.0  0.276648"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_b=pd.read_csv('5_b.csv')\n",
        "df_b.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ukYIlK-1pTk"
      },
      "outputs": [],
      "source": [
        "df_b=pd.read_csv('5_b.csv')\n",
        "df_b_proba=list(df_b[\"proba\"])\n",
        "df_b_y=list(df_b[\"y\"])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xlLVa-cVAfCS",
        "outputId": "1a52fef7-8b0c-47dd-b1f7-1476e85c7011"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "55 239 45 9761\n",
            "performance matreix is [[9761, 45], [239, 55]]\n",
            "F1 score is 0.2791878172588833\n",
            "Accuracy score is 0.9718811881188119\n",
            "AUC score is 0.062243\n"
          ]
        }
      ],
      "source": [
        "#create list of probablity values\n",
        "df_b_proba=list(df_b[\"proba\"])\n",
        "df_proba_descend=sorted(df_b_proba,reverse=True) #probablity list in descending order\n",
        "\n",
        "y_actual=list(df_b['y'])              #list of labels actual\n",
        "#create a list of tuple consisting of prob value and label\n",
        "prob_tupl=[(df_b_proba[i],y_actual[i]) for i in range (len(df_b_proba))]\n",
        "prob_tupl.sort(key=lambda x: x[0],reverse=True)       #reverse order\n",
        "\n",
        "#seperate tuple into two lists\n",
        "lst_final_proba=[]\n",
        "\n",
        "lst_final_y=[]\n",
        "for i in range (len(prob_tupl)):\n",
        "    lst_final_proba.append(prob_tupl[i][0])\n",
        "    lst_final_y.append(prob_tupl[i][1])\n",
        "\n",
        "\n",
        "y_predicted=[]              #converting prob values into labels\n",
        "for i in df_b_proba:\n",
        "    if i>=0.5:\n",
        "        y_predicted.append(1)\n",
        "    else:\n",
        "        y_predicted.append(0)\n",
        "\n",
        "def performance_matrix (list1,list2):\n",
        "    TP=0\n",
        "    FP=0\n",
        "    FN=0\n",
        "    TN=0\n",
        "    list_tn_fn=[]\n",
        "    list_fp_tp=[]\n",
        "\n",
        "    for i in range (len(list1)):\n",
        "        if list1[i]==list2[i]==1:\n",
        "            TP+=1\n",
        "        elif list1[i]==0 and list2[i]==1:\n",
        "            FP+=1\n",
        "        elif list1[i]==1 and list2[i]==0:\n",
        "            FN+=1\n",
        "        else:\n",
        "            TN+=1\n",
        "    print (TP,FP,FN,TN)\n",
        "    list_tn_fn.extend([TN,FN])\n",
        "    list_fp_tp.extend([FP,TP])\n",
        "    perform_matrix=[list_tn_fn,list_fp_tp]\n",
        "    print(\"performance matreix is\", perform_matrix)\n",
        "\n",
        "    #calculation of f1-score\n",
        "    pr=TP/(TP+FP)        #precision\n",
        "    rec=TP/(FN+TP)       #recall\n",
        "\n",
        "    f1_score=(2*pr*rec)/(pr+rec)\n",
        "    print(\"F1 score is\", f1_score)\n",
        "    accu_score=(TN+TP)/(TN+TP+FN+FP)\n",
        "    print (\"Accuracy score is\", accu_score)\n",
        "performance_matrix (y_actual,y_predicted)\n",
        "\n",
        "tpr_list=[]\n",
        "fpr_list=[]\n",
        "\n",
        "def auc_score (list1,list2):\n",
        "    new_predict=[]\n",
        "    for i in list1:\n",
        "        for j in range(len(list1)):\n",
        "            if list1[j]>=i:\n",
        "                new_predict.append(1)\n",
        "            else:\n",
        "                new_predict.append(0)\n",
        "        tp=0\n",
        "        fp=0\n",
        "        fn=0\n",
        "        tn=0\n",
        "        for k in range(len(list1)):\n",
        "            if new_predict[k]==list2[k]==1:\n",
        "                tp+=1\n",
        "            elif new_predict[k]==1 and list2[k]==0:\n",
        "                fp+=1\n",
        "            elif new_predict[k]==0 and list2[k]==1:\n",
        "                fn+=1\n",
        "            else:\n",
        "                tn+=1\n",
        "        tpr=tp/(tp+fn)\n",
        "        fpr=fp/(tn+fp)\n",
        "        tpr_list.append(tpr)\n",
        "        fpr_list.append(fpr)\n",
        "\n",
        "        new_predict=[]\n",
        "\n",
        "    trap_coordi=[]\n",
        "    for i in range(len(tpr_list)-1):\n",
        "        trap_coordi.append(((fpr_list[i]+fpr_list[i+1])/2)*(tpr_list[i+1]-tpr_list[i]))\n",
        "\n",
        "    sum=0\n",
        "    for i in range (len(trap_coordi)):\n",
        "        sum+=trap_coordi[i]\n",
        "    print (\"AUC score is\",sum)\n",
        "\n",
        "auc_score(lst_final_proba,lst_final_y)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GiPGonTzQvoB"
      },
      "source": [
        "### C. Compute the best threshold (similarly to ROC curve computation) of probability which gives lowest values of metric <b>A</b> for the given data\n",
        "<br>\n",
        "\n",
        "you will be predicting label of a data points like this: $y^{pred}= \\text{[0 if y_score < threshold  else 1]}$\n",
        "\n",
        "$ A = 500 \\times \\text{number of false negative} + 100 \\times \\text{numebr of false positive}$\n",
        "\n",
        "<pre>\n",
        "   <b>Note 1:</b> in this data you can see number of negative points > number of positive points\n",
        "   <b>Note 2:</b> use pandas or numpy to read the data from <b>5_c.csv</b>\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x5HIJzq1QvoE",
        "outputId": "a1282209-21a5-4719-9058-110a0850ed45"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2099\n"
          ]
        }
      ],
      "source": [
        "df_c=pd.read_csv('5_c.csv')\n",
        "# df_c.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eAPjewjzAfCa",
        "outputId": "952c4ca4-dab9-4bfe-869b-a67be432cd03"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2852\n",
            "2852\n",
            "The best threshold is 0.2300390278970873\n"
          ]
        }
      ],
      "source": [
        " # write your code for task C\n",
        "prob_unordered=list(df_c[\"prob\"])\n",
        "y_actual=list(df_c[\"y\"])\n",
        "\n",
        "prob_tupl=[(prob_unordered[i],y_actual[i]) for i in range (len(prob_unordered))]\n",
        "\n",
        "prob_tupl.sort(key=lambda x: x[0],reverse=True)\n",
        "prob_descend=[prob_tupl[i][0] for i in range (len(prob_tupl))]\n",
        "y_act_descend=[prob_tupl[i][1] for i in range (len(prob_tupl))]\n",
        "\n",
        "fn_list=[]\n",
        "fp_list=[]\n",
        "formula_list=[]\n",
        "def threshold (list1,list2):#list1=probab  list2= labels\n",
        "    new_predicted=[]\n",
        "    for i in list1:\n",
        "        for j in range (len(list1)):\n",
        "            if list1[j]>=i:\n",
        "                new_predicted.append(1)\n",
        "            else:\n",
        "                new_predicted.append(0)\n",
        "        fn=0\n",
        "        fp=0\n",
        "\n",
        "        for i in range (len(new_predicted)):\n",
        "            if new_predicted[i]==0 and list2[i]==1:\n",
        "                fn+=1\n",
        "            elif new_predicted[i]==1 and list2[i]==0:\n",
        "                fp+=1\n",
        "            else:\n",
        "                pass\n",
        "\n",
        "        fn_list.append(fn)\n",
        "        fp_list.append(fp)\n",
        "        new_predicted=[]\n",
        "\n",
        "    print (len(fn_list))\n",
        "    print (len(fp_list))\n",
        "\n",
        "    for i in range (len(fn_list)):\n",
        "        formula=(500*fn_list[i])+(100*fp_list[i])\n",
        "        formula_list.append(formula)\n",
        "\n",
        "    formula_tuple=[(formula_list[i],prob_descend[i]) for i in range (len(formula_list))]\n",
        "    formula_tuple.sort(key=lambda x: x[0])\n",
        "\n",
        "    print(\"The best threshold is\",formula_tuple[0][1])\n",
        "\n",
        "\n",
        "\n",
        "threshold (prob_descend,y_act_descend)\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sD4CcgjXQvoL"
      },
      "source": [
        "\n",
        "## D.</b></font> Compute performance metrics(for regression) for the given data 5_d.csv\n",
        "<pre>    <b>Note 2:</b> use pandas or numpy to read the data from <b>5_d.csv</b>\n",
        "    <b>Note 1:</b> <b>5_d.csv</b> will having two columns Y and predicted_Y both are real valued features\n",
        "<ol>\n",
        "<li> Compute Mean Square Error </li>\n",
        "<li> Compute MAPE: https://www.youtube.com/watch?v=ly6ztgIkUxk</li>\n",
        "<li> Compute R^2 error: https://en.wikipedia.org/wiki/Coefficient_of_determination#Definitions </li>\n",
        "</ol>\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sVOj-bF9AfCd",
        "outputId": "9526a891-e963-49f2-d6c0-769f06fe9092"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5717\n"
          ]
        }
      ],
      "source": [
        "df_d=pd.read_csv('5_d.csv')\n",
        "df_d.head()\n",
        "y_actual= list(df_d[\"y\"])\n",
        "# y_actual\n",
        "y_predicted=list(df_d[\"pred\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uRhL1pheAfCe",
        "outputId": "28572269-c983-4970-e782-9deadd509001"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The mean square error is 177.16569974554707\n",
            "The mean absolute percentage error is 31.603038298134713\n",
            "The R-squared error is 0.9563582786990937\n"
          ]
        }
      ],
      "source": [
        " # write your code for task 5d\n",
        "y_actual= list(df_d[\"y\"])\n",
        "y_predicted=list(df_d[\"pred\"])\n",
        "\n",
        "list_mse=[]     #list for mse\n",
        "list_replace_zero=[]     #modified list for countering 0\n",
        "list_mape=[]     #list for mape\n",
        "list_ss_total=[]     #list for ss total\n",
        "list_ss_res=[]     #list for ss resid\n",
        "def perform_matrix_regression (list1,list2):\n",
        "    y_act_avg=np.mean(list1)\n",
        "    for i in range (len(list1)):\n",
        "        list_mse.append(((list1[i]-list2[i]))**2)\n",
        "    mse=np.mean(list_mse)\n",
        "    print (\"The mean square error is\",mse)\n",
        "\n",
        "    for i in list1:\n",
        "        if i>0:\n",
        "            list_replace_zero.append(i)\n",
        "        else:\n",
        "            list_replace_zero.append(y_act_avg)\n",
        "\n",
        "    for i in range (len(list_replace_zero)):\n",
        "        list_mape.append((abs(list_replace_zero[i]-list2[i])/list_replace_zero[i])*100)\n",
        "    mape=np.mean(list_mape)\n",
        "    print (\"The mean absolute percentage error is\",mape)\n",
        "\n",
        "    for i in range (len(list1)):\n",
        "        list_ss_total.append((list1[i]-y_act_avg)**2)\n",
        "        list_ss_res.append((list1[i]-list2[i])**2)\n",
        "    ss_total=np.sum(list_ss_total)\n",
        "    ss_res=np.sum(list_ss_res)\n",
        "    r_square_error=(1-(ss_res/ss_total))\n",
        "\n",
        "    print (\"The R-squared error is\",r_square_error)\n",
        "\n",
        "\n",
        "\n",
        "perform_matrix_regression (y_actual,y_predicted)\n",
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}